# Machine Learning Models - Regression & Classification
# Dá»± Ä‘oÃ¡n PM2.5 vÃ  phÃ¢n loáº¡i cháº¥t lÆ°á»£ng khÃ´ng khÃ­ TP.HCM

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import (mean_squared_error, r2_score, mean_absolute_error,
                           classification_report, confusion_matrix, accuracy_score)
import warnings
warnings.filterwarnings('ignore')

print("=== MACHINE LEARNING MODELS - TASK 4 & 5 ===")
print("ğŸ¯ Má»¥c tiÃªu: Dá»± Ä‘oÃ¡n PM2.5 (Regression) + PhÃ¢n loáº¡i AQI (Classification)")

# 1. Äá»ŒC Dá»® LIá»†U ÄÃƒ ÄÆ¯á»¢C LÃ€M Sáº CH
try:
    df = pd.read_csv("cleaned_data.csv")
    print(f"ğŸ“Š Dá»¯ liá»‡u sáº¡ch: {df.shape[0]:,} dÃ²ng, {df.shape[1]} cá»™t")
except:
    print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y cleaned_data.csv, sá»­ dá»¥ng dá»¯ liá»‡u gá»‘c...")
    df = pd.read_csv("HealthyAir_HCMC.csv")
    
    # Táº¡o láº¡i AQI Level náº¿u cáº§n
    def create_aqi_level(pm25):
        if pm25 <= 12:
            return 'Good'
        elif pm25 <= 35.4:
            return 'Moderate'
        elif pm25 <= 55.4:
            return 'Unhealthy'
        else:
            return 'Hazardous'
    
    df['AQI_Level'] = df['PM2.5'].apply(create_aqi_level)
    df = df.dropna(subset=['PM2.5', 'TSP', 'Temperature', 'Humidity'])
    print(f"ğŸ“Š Dá»¯ liá»‡u sau lÃ m sáº¡ch: {df.shape[0]:,} dÃ²ng")

# 2. CHUáº¨N Bá»Š Dá»® LIá»†U CHO MACHINE LEARNING
print(f"\nğŸ”§ CHUáº¨N Bá»Š Dá»® LIá»†U:")

# Features (X) - cÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng Ä‘áº¿n cháº¥t lÆ°á»£ng khÃ´ng khÃ­
feature_columns = ['TSP', 'O3', 'CO', 'NO2', 'SO2', 'Temperature', 'Humidity', 'Station_No']
available_features = [col for col in feature_columns if col in df.columns and df[col].notna().sum() > 1000]
print(f"ğŸ“‹ Features sá»­ dá»¥ng: {available_features}")

X = df[available_features].copy()
y_regression = df['PM2.5'].copy()  # Target cho regression
y_classification = df['AQI_Level'].copy()  # Target cho classification

# Xá»­ lÃ½ missing values cho features
for col in X.columns:
    if X[col].isnull().sum() > 0:
        X[col].fillna(X[col].median(), inplace=True)
        print(f"  âœ… Äiá»n missing values cho {col}: {X[col].isnull().sum()} â†’ 0")

# Kiá»ƒm tra dá»¯ liá»‡u cuá»‘i cÃ¹ng
valid_indices = y_regression.notna() & y_classification.notna()
X = X[valid_indices]
y_regression = y_regression[valid_indices]
y_classification = y_classification[valid_indices]

print(f"ğŸ“Š Dá»¯ liá»‡u cuá»‘i cÃ¹ng: {X.shape[0]:,} samples, {X.shape[1]} features")
print(f"ğŸ“ˆ AQI Level distribution:")
aqi_dist = y_classification.value_counts()
for level, count in aqi_dist.items():
    print(f"  {level}: {count:,} ({count/len(y_classification)*100:.1f}%)")

# 3. CHIA Táº¬P TRAIN/TEST
X_train, X_test, y_train_reg, y_test_reg = train_test_split(
    X, y_regression, test_size=0.2, random_state=42, stratify=pd.qcut(y_regression, q=5, duplicates='drop'))

_, _, y_train_class, y_test_class = train_test_split(
    X, y_classification, test_size=0.2, random_state=42, stratify=y_classification)

# Chuáº©n hÃ³a dá»¯ liá»‡u
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"\nğŸ“Š Chia táº­p dá»¯ liá»‡u:")
print(f"  Training: {X_train.shape[0]:,} samples")
print(f"  Testing: {X_test.shape[0]:,} samples")

# 4. TASK 4: REGRESSION MODELS - Dá»° ÄOÃN PM2.5
print(f"\nğŸ¯ TASK 4: REGRESSION MODELS")
print("="*50)

regression_results = {}

# 4.1 Linear Regression
print("ğŸ“Š 1. LINEAR REGRESSION")
lr_model = LinearRegression()
lr_model.fit(X_train_scaled, y_train_reg)
y_pred_lr = lr_model.predict(X_test_scaled)

# ÄÃ¡nh giÃ¡ Linear Regression
lr_rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_lr))
lr_r2 = r2_score(y_test_reg, y_pred_lr)
lr_mae = mean_absolute_error(y_test_reg, y_pred_lr)

print(f"  ğŸ“ˆ RMSE: {lr_rmse:.2f}")
print(f"  ğŸ“ˆ RÂ² Score: {lr_r2:.3f}")
print(f"  ğŸ“ˆ MAE: {lr_mae:.2f}")

regression_results['Linear Regression'] = {
    'RMSE': lr_rmse, 'R2': lr_r2, 'MAE': lr_mae, 'predictions': y_pred_lr
}

# 4.2 Random Forest Regression
print(f"\nğŸ“Š 2. RANDOM FOREST REGRESSION")
rf_reg_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
rf_reg_model.fit(X_train, y_train_reg)  # KhÃ´ng cáº§n scaling cho RF
y_pred_rf_reg = rf_reg_model.predict(X_test)

# ÄÃ¡nh giÃ¡ Random Forest Regression
rf_reg_rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_rf_reg))
rf_reg_r2 = r2_score(y_test_reg, y_pred_rf_reg)
rf_reg_mae = mean_absolute_error(y_test_reg, y_pred_rf_reg)

print(f"  ğŸ“ˆ RMSE: {rf_reg_rmse:.2f}")
print(f"  ğŸ“ˆ RÂ² Score: {rf_reg_r2:.3f}")
print(f"  ğŸ“ˆ MAE: {rf_reg_mae:.2f}")

regression_results['Random Forest'] = {
    'RMSE': rf_reg_rmse, 'R2': rf_reg_r2, 'MAE': rf_reg_mae, 'predictions': y_pred_rf_reg
}

# 5. TASK 5: CLASSIFICATION MODELS - PHÃ‚N LOáº I AQI
print(f"\nğŸ¯ TASK 5: CLASSIFICATION MODELS")
print("="*50)

classification_results = {}

# 5.1 Random Forest Classification
print("ğŸ“Š 1. RANDOM FOREST CLASSIFICATION")
rf_class_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
rf_class_model.fit(X_train, y_train_class)
y_pred_rf_class = rf_class_model.predict(X_test)

# ÄÃ¡nh giÃ¡ Random Forest Classification
rf_class_accuracy = accuracy_score(y_test_class, y_pred_rf_class)
print(f"  ğŸ“ˆ Accuracy: {rf_class_accuracy:.3f}")
print(f"\nğŸ“‹ Classification Report:")
print(classification_report(y_test_class, y_pred_rf_class))

classification_results['Random Forest'] = {
    'accuracy': rf_class_accuracy, 'predictions': y_pred_rf_class, 'model': rf_class_model
}

# 5.2 Decision Tree Classification
print(f"\nğŸ“Š 2. DECISION TREE CLASSIFICATION")
dt_model = DecisionTreeClassifier(random_state=42, max_depth=10)
dt_model.fit(X_train, y_train_class)
y_pred_dt = dt_model.predict(X_test)

# ÄÃ¡nh giÃ¡ Decision Tree
dt_accuracy = accuracy_score(y_test_class, y_pred_dt)
print(f"  ğŸ“ˆ Accuracy: {dt_accuracy:.3f}")
print(f"\nğŸ“‹ Classification Report:")
print(classification_report(y_test_class, y_pred_dt))

classification_results['Decision Tree'] = {
    'accuracy': dt_accuracy, 'predictions': y_pred_dt, 'model': dt_model
}

# 6. FEATURE IMPORTANCE ANALYSIS (Task 6)
print(f"\nğŸ¯ TASK 6: FEATURE IMPORTANCE ANALYSIS")
print("="*50)

# Feature importance tá»« Random Forest Regression
print("ğŸ“Š FEATURE IMPORTANCE - REGRESSION (PM2.5 Prediction):")
feature_importance_reg = pd.DataFrame({
    'feature': available_features,
    'importance': rf_reg_model.feature_importances_
}).sort_values('importance', ascending=False)

for idx, row in feature_importance_reg.iterrows():
    print(f"  {row['feature']}: {row['importance']:.3f}")

# Feature importance tá»« Random Forest Classification
print(f"\nğŸ“Š FEATURE IMPORTANCE - CLASSIFICATION (AQI Level):")
feature_importance_class = pd.DataFrame({
    'feature': available_features,
    'importance': rf_class_model.feature_importances_
}).sort_values('importance', ascending=False)

for idx, row in feature_importance_class.iterrows():
    print(f"  {row['feature']}: {row['importance']:.3f}")

# 7. VISUALIZATIONS
print(f"\nğŸ“Š CREATING VISUALIZATIONS...")

# Táº¡o figure cho táº¥t cáº£ cÃ¡c plots
fig = plt.figure(figsize=(20, 15))

# Plot 1: Regression Results Comparison
plt.subplot(3, 3, 1)
models = list(regression_results.keys())
rmse_values = [regression_results[model]['RMSE'] for model in models]
r2_values = [regression_results[model]['R2'] for model in models]

x = np.arange(len(models))
width = 0.35
plt.bar(x - width/2, rmse_values, width, label='RMSE', alpha=0.8)
plt.bar(x + width/2, [r2*50 for r2 in r2_values], width, label='RÂ²Ã—50', alpha=0.8)
plt.xlabel('MÃ´ hÃ¬nh')
plt.ylabel('Äiá»ƒm sá»‘')
plt.title('So sÃ¡nh cÃ¡c mÃ´ hÃ¬nh Regression')
plt.xticks(x, models)
plt.legend()

# Plot 2: Actual vs Predicted (Best Regression Model)
plt.subplot(3, 3, 2)
best_reg_model = 'Random Forest' if rf_reg_r2 > lr_r2 else 'Linear Regression'
best_predictions = regression_results[best_reg_model]['predictions']
plt.scatter(y_test_reg, best_predictions, alpha=0.5, s=20)
plt.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)
plt.xlabel('Thá»±c táº¿ PM2.5')
plt.ylabel('Dá»± Ä‘oÃ¡n PM2.5')
plt.title(f'Thá»±c táº¿ vs Dá»± Ä‘oÃ¡n - {best_reg_model}')

# Plot 3: Feature Importance - Regression
plt.subplot(3, 3, 3)
top_features_reg = feature_importance_reg.head(7)
plt.barh(top_features_reg['feature'], top_features_reg['importance'])
plt.xlabel('Má»©c Ä‘á»™ quan trá»ng')
plt.title('Táº§m quan trá»ng cá»§a biáº¿n - Regression')

# Plot 4: Classification Accuracy Comparison
plt.subplot(3, 3, 4)
class_models = list(classification_results.keys())
class_accuracies = [classification_results[model]['accuracy'] for model in class_models]
bars = plt.bar(class_models, class_accuracies, color=['skyblue', 'lightcoral'])
plt.ylabel('Äá»™ chÃ­nh xÃ¡c')
plt.title('So sÃ¡nh cÃ¡c mÃ´ hÃ¬nh Classification')
plt.ylim(0, 1)
for i, bar in enumerate(bars):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
             f'{class_accuracies[i]:.3f}', ha='center')

# Plot 5: Confusion Matrix (Best Classification Model)
plt.subplot(3, 3, 5)
best_class_model = 'Random Forest' if rf_class_accuracy > dt_accuracy else 'Decision Tree'
best_class_predictions = classification_results[best_class_model]['predictions']
cm = confusion_matrix(y_test_class, best_class_predictions)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Tá»‘t', 'Vá»«a', 'KÃ©m', 'Nguy háº¡i'],
            yticklabels=['Tá»‘t', 'Vá»«a', 'KÃ©m', 'Nguy háº¡i'])
plt.xlabel('Dá»± Ä‘oÃ¡n')
plt.ylabel('Thá»±c táº¿')
plt.title(f'Ma tráº­n nháº§m láº«n - {best_class_model}')

# Plot 6: Feature Importance - Classification
plt.subplot(3, 3, 6)
top_features_class = feature_importance_class.head(7)
plt.barh(top_features_class['feature'], top_features_class['importance'], color='orange')
plt.xlabel('Má»©c Ä‘á»™ quan trá»ng')
plt.title('Táº§m quan trá»ng cá»§a biáº¿n - Classification')

# Plot 7: Prediction Error Distribution
plt.subplot(3, 3, 7)
errors = y_test_reg - best_predictions
plt.hist(errors, bins=30, alpha=0.7, color='green')
plt.xlabel('Sai sá»‘ dá»± Ä‘oÃ¡n')
plt.ylabel('Táº§n suáº¥t')
plt.title('PhÃ¢n bá»‘ sai sá»‘ dá»± Ä‘oÃ¡n')

# Plot 8: AQI Level Prediction Accuracy by Class
plt.subplot(3, 3, 8)
class_accuracy_detail = []
for level in ['Good', 'Moderate', 'Unhealthy', 'Hazardous']:
    if level in y_test_class.values:
        mask = y_test_class == level
        if mask.sum() > 0:
            acc = (y_test_class[mask] == best_class_predictions[mask]).mean()
            class_accuracy_detail.append((level, acc))

if class_accuracy_detail:
    levels, accs = zip(*class_accuracy_detail)
    colors = ['green', 'yellow', 'orange', 'red'][:len(levels)]
    bars = plt.bar(levels, accs, color=colors, alpha=0.7)
    plt.ylabel('Äá»™ chÃ­nh xÃ¡c')
    plt.title('Äá»™ chÃ­nh xÃ¡c theo má»©c AQI')
    plt.xticks(rotation=45)
    for i, bar in enumerate(bars):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                 f'{accs[i]:.2f}', ha='center')

# Plot 9: Model Performance Summary
plt.subplot(3, 3, 9)
summary_data = {
    'Regression': [f'Best: {best_reg_model}', 
                   f'RMSE: {regression_results[best_reg_model]["RMSE"]:.2f}',
                   f'RÂ²: {regression_results[best_reg_model]["R2"]:.3f}'],
    'Classification': [f'Best: {best_class_model}',
                      f'Accuracy: {classification_results[best_class_model]["accuracy"]:.3f}',
                      f'Classes: {len(np.unique(y_test_class))}']
}
plt.text(0.1, 0.8, 'MODEL PERFORMANCE SUMMARY', fontsize=14, weight='bold', transform=plt.gca().transAxes)
plt.text(0.1, 0.6, '\n'.join([f'{k}: {", ".join(v)}' for k, v in summary_data.items()]), 
         fontsize=10, transform=plt.gca().transAxes)
plt.axis('off')

plt.tight_layout()
plt.savefig('ml_models_results.png', dpi=300, bbox_inches='tight')
plt.show()

# 8. Káº¾T LUáº¬N VÃ€ LÆ¯U Káº¾T QUáº¢
print(f"\nğŸ‰ Káº¾T QUáº¢ MACHINE LEARNING:")
print("="*50)
print(f"ğŸ”¹ REGRESSION (Dá»± Ä‘oÃ¡n PM2.5):")
print(f"  Best Model: {best_reg_model}")
print(f"  RMSE: {regression_results[best_reg_model]['RMSE']:.2f} Î¼g/mÂ³")
print(f"  RÂ² Score: {regression_results[best_reg_model]['R2']:.3f}")
print(f"  MAE: {regression_results[best_reg_model]['MAE']:.2f} Î¼g/mÂ³")

print(f"\nğŸ”¹ CLASSIFICATION (PhÃ¢n loáº¡i AQI):")
print(f"  Best Model: {best_class_model}")
print(f"  Overall Accuracy: {classification_results[best_class_model]['accuracy']:.3f}")

print(f"\nğŸ”¹ TOP 3 Yáº¾U Tá» áº¢NH HÆ¯á»NG NHáº¤T:")
print("  Regression:")
for i, (_, row) in enumerate(feature_importance_reg.head(3).iterrows()):
    print(f"    {i+1}. {row['feature']}: {row['importance']:.3f}")
print("  Classification:")
for i, (_, row) in enumerate(feature_importance_class.head(3).iterrows()):
    print(f"    {i+1}. {row['feature']}: {row['importance']:.3f}")

# LÆ°u káº¿t quáº£ Ä‘á»ƒ sá»­ dá»¥ng cho forecast
results_summary = {
    'best_regression_model': best_reg_model,
    'best_classification_model': best_class_model,
    'feature_columns': available_features,
    'regression_performance': regression_results[best_reg_model],
    'classification_performance': classification_results[best_class_model],
    'feature_importance_reg': feature_importance_reg.to_dict(),
    'feature_importance_class': feature_importance_class.to_dict()
}

import pickle
with open('ml_results.pkl', 'wb') as f:
    pickle.dump(results_summary, f)
    
print(f"\nğŸ’¾ Saved results to 'ml_results.pkl'")
print(f"âœ… Task 4, 5, 6 COMPLETED!")
print(f"ğŸš€ Ready for Task 7: Time Series Forecasting 2025")